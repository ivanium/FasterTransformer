Inside docker
/FasterTransformer/build /home/gedatsu/FasterTransformer/scripts
Running mnfd_llama with default config.ini
[FT][WARNING] Skip NCCL initialization since requested tensor/pipeline parallel sizes are equals to 1.
Total ranks: 1.
Device NVIDIA A100-SXM4-40GB
P0-0 is running with GPU #0.
Device NVIDIA A100-SXM4-40GB
P0-1 is running with GPU #1.
[WARNING] gemm_config.in is not found; using default GEMM algo
[WARNING] gemm_config.in is not found; using default GEMM algo
after allocation    : free: 32.41 GB, total: 39.39 GB, used:  6.98 GB
after allocation    : free: 32.41 GB, total: 39.39 GB, used:  6.98 GB
Writing 100 elements
    1   450  7483   310  7551   338  1522   823   292 29889 
zeroCount = 0
[INFO] request_batch_size 1 beam_width 1 head_num 32 size_per_head 128 total_output_len 100 decoder_layers 32 vocab_size 32000 FT-CPP-decoding-beamsearch-time 1320.92 ms
[INFO] request_batch_size 1 beam_width 1 head_num 32 size_per_head 128 total_output_len 100 decoder_layers 32 vocab_size 32000 FT-CPP-decoding-beamsearch-time 1320.92 ms
/home/gedatsu/FasterTransformer/scripts
"<s> The capital of China is Beijing. The capital of the United States is Washington, D.C. The capital of France is Paris. The capital of the United Kingdom is London. The capital of Russia is Moscow. The capital of Germany is Berlin. The capital of Italy is Rome. The capital of Spain is Madrid. The capital of Japan is Tokyo. The capital of Australia is Canberra. The capital of Canada is Ottawa. The capital of Brazil is Brasilia. The"
